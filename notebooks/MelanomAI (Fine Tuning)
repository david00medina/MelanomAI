{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MelanomAI (Fine Tuning)","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"x7ow6HLOdZPM","colab_type":"text"},"source":["# MelanomAI (Fine Tuning)\n","\n","Este modelo integra una red _VGG16_ a la que hemos añadido una red _fully-connected_ en sus últimas capas. La clasificación se hará sobre 8 tipos de clases de lesiones cutáneas distintas.\n"]},{"cell_type":"code","metadata":{"id":"uIJaiVL3dmXk","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.models                import Sequential, Model, load_model\n","from tensorflow.keras.layers                import Dense, Input, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n","from tensorflow.keras.layers                import Conv2DTranspose, UpSampling2D, MaxPooling2D, Reshape, Activation, ReLU\n","from tensorflow.keras.preprocessing.image   import ImageDataGenerator\n","from tensorflow.keras.utils                 import to_categorical\n","from tensorflow.keras.optimizers            import Adam, SGD\n","from sklearn.metrics                        import confusion_matrix \n","import itertools\n","\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","%matplotlib inline\n","\n","#from api.isic_api import ISICApi\n","#!rm -rf dataset/train/DatosExtra\n","#!rm -rf dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJjh1G-4EmkP","colab_type":"text"},"source":["Cargamos la carpeta del proyecto del __Google Drive__."]},{"cell_type":"code","metadata":{"id":"1UtHjYtZEuu6","colab_type":"code","outputId":"b8ab8d82-2631-4748-f1c3-c494077e7e05","executionInfo":{"status":"ok","timestamp":1562941617538,"user_tz":-60,"elapsed":269591,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#!unzip /content/drive/My\\ Drive/Trabajo\\ Machine\\ Learning/dataset_8.zip"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"05bXJ42ud409","colab_type":"text"},"source":["## Diseño de la arquitectura\n","\n","Cargamos el modelo VGG16 preentrenado con ImageNet de la librería _TensorFlow_. Evitamos que las capas de la _VGG16_ se reentrenen."]},{"cell_type":"code","metadata":{"id":"V0taISApeBMg","colab_type":"code","outputId":"012e8737-e20f-40f7-f068-f3752faa05e6","executionInfo":{"status":"ok","timestamp":1562941994844,"user_tz":-60,"elapsed":3253,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}},"colab":{"base_uri":"https://localhost:8080/","height":815}},"source":["vgg16_model = tf.keras.applications.vgg16.VGG16(include_top=False, \n","                                                weights='imagenet',\n","                                                input_shape=(300,300,3))\n","vgg16_model.summary()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 300, 300, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"um7QIS4ce1-6","colab_type":"text"},"source":["Aplicamos la técnica de _Transfer Learning_ con el objeto de optimizar el tiempo de de entrenamiento de la red convolutiva. Para ello, tendremos que cargar las primeras capas de la red _VGG16_, salvo la última, a partir de la cuál insertaremos nuestra red CNN de juguete con el que obtuvimos un _accuracy_ del ~13%."]},{"cell_type":"code","metadata":{"id":"QSglvfqjf2hh","colab_type":"code","outputId":"65e05678-e76e-4727-eb55-500e942114f3","executionInfo":{"status":"ok","timestamp":1562941995611,"user_tz":-60,"elapsed":1723,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}},"colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["model = Sequential()\n","\n","model.add(vgg16_model)\n","\n","# Adjuntar modelo a VGG16\n","# model.add(Conv2D(16, (3, 3), input_shape=(9,9,512)))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","# model.add(Activation('relu'))\n","# \n","# model.add(Conv2D(32, (3, 3)))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","# model.add(Activation('relu'))\n","# \n","# model.add(Conv2D(64, (3, 3)))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","# model.add(Activation('relu'))\n","# \n","# model.add(Conv2D(128, (3, 3)))\n","# model.add(MaxPooling2D(pool_size=(2, 2)))\n","# model.add(Activation('relu'))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(64))\n","model.add(Dense(8, activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=SGD(0.001), \n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Model)                (None, 9, 9, 512)         14714688  \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 41472)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               10617088  \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 256)               0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 8)                 520       \n","=================================================================\n","Total params: 25,373,448\n","Trainable params: 25,373,448\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wKHwhuTw72mY","colab_type":"text"},"source":["## Carga de los datos\n","\n","Se procede con la carga de los datos de entrenamiento, validación y test."]},{"cell_type":"code","metadata":{"id":"YiZHhOAD8EPl","colab_type":"code","outputId":"5efad78d-7e6f-4406-f326-3f223737d243","executionInfo":{"status":"ok","timestamp":1562941999634,"user_tz":-60,"elapsed":2241,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["\n","DATASET_PATH = 'dataset'\n","\n","# Cargamos los datos de entrenamiento y test\n","\n","datagen = ImageDataGenerator(rescale=1./255)\n","train_batches = datagen.flow_from_directory(DATASET_PATH + \"/train\" ,target_size=(300,300), batch_size=32, class_mode='categorical')\n","\n","datagen2 = ImageDataGenerator(rescale=1./255)\n","val_batches = datagen2.flow_from_directory(DATASET_PATH +  '/validation' ,target_size=(300,300), batch_size=32, class_mode='categorical')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Found 12873 images belonging to 8 classes.\n","Found 6242 images belonging to 8 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p26IitUU8PZN","colab_type":"text"},"source":["## Entrenamiento\n","\n","Se procede con el entrenamiento del la red."]},{"cell_type":"code","metadata":{"id":"9ZG7FSBl8TY8","colab_type":"code","outputId":"ebf78194-f895-4d5a-97d1-60959cbcf270","executionInfo":{"status":"ok","timestamp":1562941617325,"user_tz":-60,"elapsed":289357,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}},"colab":{"base_uri":"https://localhost:8080/","height":401}},"source":["cp_callback = tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5', \n","                                                 monitor='val_acc',\n","                                                 verbose=1)\n","model.fit_generator(train_batches, steps_per_epoch=20, epochs=5, \n","                    validation_data=val_batches, validation_steps=10,\n","                   callbacks=[cp_callback])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","19/20 [===========================>..] - ETA: 1:43 - loss: 2.1194 - acc: 0.2303\n","Epoch 00001: saving model to /content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5\n","20/20 [==============================] - 2352s 118s/step - loss: 2.1050 - acc: 0.2406 - val_loss: 1.8795 - val_acc: 0.3187\n","Epoch 2/5\n","19/20 [===========================>..] - ETA: 1:42 - loss: 1.8909 - acc: 0.3487\n","Epoch 00002: saving model to /content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5\n","20/20 [==============================] - 2345s 117s/step - loss: 1.8928 - acc: 0.3453 - val_loss: 1.8585 - val_acc: 0.3375\n","Epoch 3/5\n","19/20 [===========================>..] - ETA: 1:42 - loss: 1.8758 - acc: 0.3109\n","Epoch 00003: saving model to /content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5\n","20/20 [==============================] - 2339s 117s/step - loss: 1.8985 - acc: 0.3063 - val_loss: 1.8586 - val_acc: 0.3500\n","Epoch 4/5\n","19/20 [===========================>..] - ETA: 1:42 - loss: 1.8045 - acc: 0.3750\n","Epoch 00004: saving model to /content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5\n","20/20 [==============================] - 2342s 117s/step - loss: 1.8024 - acc: 0.3734 - val_loss: 1.8007 - val_acc: 0.3438\n","Epoch 5/5\n","19/20 [===========================>..] - ETA: 1:42 - loss: 1.8327 - acc: 0.3618\n","Epoch 00005: saving model to /content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5\n","20/20 [==============================] - 2432s 122s/step - loss: 1.8362 - acc: 0.3562 - val_loss: 1.7848 - val_acc: 0.3625\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7eff840aca90>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"uHhCZZAaFoeb","colab_type":"text"},"source":["## Predicción y resultados\n","\n","Cargamos el modelo del __Google Drive__."]},{"cell_type":"code","metadata":{"id":"06PM51HDAqjo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"62416335-1e54-4133-87ee-168bc20a2b27","executionInfo":{"status":"ok","timestamp":1562942028306,"user_tz":-60,"elapsed":9114,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}}},"source":["trained_model = load_model('/content/drive/My Drive/Trabajo Machine Learning/weights/vgg16_ft.h5')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["W0712 14:33:45.231688 139637112973184 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0712 14:33:45.243846 139637112973184 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"lcAzU8k1wMJ1","colab_type":"text"},"source":["Función utilizada para imprimir todas las imágenes de un batch con sus etiquetas asociadas. Se plotea una pequeña muestra de las imágenes de test con su predicción asociada."]},{"cell_type":"code","metadata":{"id":"RliSCOR5wTO6","colab_type":"code","colab":{}},"source":["def plots(ims, figsize=(100,100), rows=1, interp=False, titles=None):\n","  class_name = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n","  if type(ims[0]) is np.ndarray:\n","    ims = np.array(ims).astype(np.uint8)\n","    if (ims.shape[-1] != 3):\n","      ims = ims.transpose((0,2,3,1))\n","      \n","  f = plt.figure(figsize=figsize)\n","  \n","  cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows+1\n","  for i in range(len(ims)):\n","    sp = f.add_subplot(rows, cols, i+1)\n","    sp.axis('Off')\n","    \n","    j = np.where(titles[i]==1)[0][0]\n","    if titles is not None:\n","      sp.set_title(class_name[j], fontsize=16)\n","    plt.imshow(ims[i], interpolation=None if interp else 'none')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GIWYOb8AFyjd","colab_type":"code","outputId":"5435073f-f25e-4754-b437-cc511fd782df","executionInfo":{"status":"ok","timestamp":1562889029053,"user_tz":-60,"elapsed":135247,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["datagen3 = ImageDataGenerator(rescale=1./255)\n","test_batches = datagen3.flow_from_directory(DATASET_PATH +  '/test' ,target_size=(300,300), batch_size=128, class_mode='categorical')\n","\n","test_img,test_labels =  next(test_batches)\n","predictions = np.array(model.predict_generator(test_batches, steps=1, verbose=0))\n","plots(test_img*255, titles=test_labels)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 2916 images belonging to 8 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dSARSykPeVNx","colab_type":"text"},"source":["Se muestran los resultados en una matriz de confusión y la tasa de éxito sobre el conjunto de _test_."]},{"cell_type":"code","metadata":{"id":"AC1HyFgI1kJh","colab_type":"code","colab":{}},"source":["def plot_confusion_matrix(cm, classes, normalize=False, title='Matriz de confusión (VGG16)', cmap=plt.cm.Blues):\n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  plt.title(title)\n","  plt.colorbar()\n","  tick_marks = np.arange(len(classes))\n","  plt.xticks(tick_marks, classes, rotation=45)\n","  plt.yticks(tick_marks, classes)\n","  \n","  if normalize:\n","    cm= cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    print('Matrix de confusión normalizada')\n","  else:\n","    print('Matriz de confusión sin normalizar')\n","    \n","  #print(cm)\n","  \n","  thresh = cm.max() / 2.\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, cm[i,j],\n","              horizontalalignment='center',\n","              color='white' if cm[i,j] > thresh else 'black')\n","              \n","  plt.tight_layout()\n","  plt.ylabel('Lesión correcta')\n","  plt.xlabel('Lesión predecida')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVyyulV5dK_S","colab_type":"code","colab":{}},"source":["def success_rate(test, pred):\n","  success = 0\n","  for i, j in zip(test, pred):\n","    if i == j:\n","      success = success + 1\n","  print(\"Test accuracy: \", success/len(test)*100, '%')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"srrYV3WtC5m5","colab_type":"code","colab":{}},"source":["labels = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n","\n","rounded_pred = np.argmax(predictions, axis=1)\n","rounded_test_labels = np.argmax(test_labels, axis=1)\n","print(test_labels)\n","print(rounded_test_labels)\n","print(rounded_pred)\n","cm = confusion_matrix(rounded_test_labels,rounded_pred)\n","\n","plot_confusion_matrix(cm, labels, title='Matriz de confusión:\\nVGG16 con Transfer Learning')\n","model.evaluate_generator(test_batches)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fjkvjtsm_mC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":166},"outputId":"9f932909-484c-4346-9843-f1d8dc485ab7","executionInfo":{"status":"error","timestamp":1562942774993,"user_tz":-60,"elapsed":955,"user":{"displayName":"David Alberto Medina Medina","photoUrl":"https://lh6.googleusercontent.com/-YofkqhrIWAs/AAAAAAAAAAI/AAAAAAAAAY8/EVyCTgluI5Y/s64/photo.jpg","userId":"09462396824708322180"}}},"source":[""],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-999689dcc75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"]}]}]}